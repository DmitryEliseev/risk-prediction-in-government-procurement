{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53979, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valID</th>\n",
       "      <th>cntrID</th>\n",
       "      <th>supID</th>\n",
       "      <th>orgID</th>\n",
       "      <th>okpdID</th>\n",
       "      <th>sup_cntr_num</th>\n",
       "      <th>sup_running_cntr_num</th>\n",
       "      <th>sup_cntr_avg_price</th>\n",
       "      <th>sup_cntr_avg_penalty_share</th>\n",
       "      <th>sup_no_pnl_share</th>\n",
       "      <th>...</th>\n",
       "      <th>sup_mun_cntr_share</th>\n",
       "      <th>sup_okpd_exp</th>\n",
       "      <th>org_good_cntr_share</th>\n",
       "      <th>org_fed_cntr_share</th>\n",
       "      <th>org_sub_cntr_share</th>\n",
       "      <th>org_mun_cntr_share</th>\n",
       "      <th>okpd_good_cntr_share</th>\n",
       "      <th>quarter</th>\n",
       "      <th>cntr_length</th>\n",
       "      <th>one_day_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57692890</td>\n",
       "      <td>32352291</td>\n",
       "      <td>10135334</td>\n",
       "      <td>467566</td>\n",
       "      <td>153861</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>165150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.990060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.011099</td>\n",
       "      <td>2</td>\n",
       "      <td>233</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211683097</td>\n",
       "      <td>34748597</td>\n",
       "      <td>10490076</td>\n",
       "      <td>480718</td>\n",
       "      <td>151943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>255590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010274</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58994828</td>\n",
       "      <td>32503663</td>\n",
       "      <td>10147390</td>\n",
       "      <td>520420</td>\n",
       "      <td>151705</td>\n",
       "      <td>217</td>\n",
       "      <td>162</td>\n",
       "      <td>60633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603687</td>\n",
       "      <td>0.968401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.036036</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208185735</td>\n",
       "      <td>40043960</td>\n",
       "      <td>10197821</td>\n",
       "      <td>207848</td>\n",
       "      <td>150662</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>187902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.993682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.079040</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>5752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59431305</td>\n",
       "      <td>33698468</td>\n",
       "      <td>10326174</td>\n",
       "      <td>90470</td>\n",
       "      <td>157012</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>180288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.070969</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       valID    cntrID     supID   orgID  okpdID  sup_cntr_num  \\\n",
       "0   57692890  32352291  10135334  467566  153861             6   \n",
       "1  211683097  34748597  10490076  480718  151943             1   \n",
       "2   58994828  32503663  10147390  520420  151705           217   \n",
       "3  208185735  40043960  10197821  207848  150662             3   \n",
       "4   59431305  33698468  10326174   90470  157012             3   \n",
       "\n",
       "   sup_running_cntr_num  sup_cntr_avg_price  sup_cntr_avg_penalty_share  \\\n",
       "0                     3              165150                         0.0   \n",
       "1                     0              255590                         0.0   \n",
       "2                   162               60633                         0.0   \n",
       "3                     0              187902                         0.0   \n",
       "4                     0              180288                         0.0   \n",
       "\n",
       "   sup_no_pnl_share      ...        sup_mun_cntr_share  sup_okpd_exp  \\\n",
       "0               1.0      ...                  0.000000      0.166667   \n",
       "1               1.0      ...                  0.000000      1.000000   \n",
       "2               1.0      ...                  0.000000      0.603687   \n",
       "3               1.0      ...                  0.333333      0.666667   \n",
       "4               1.0      ...                  0.000000      0.666667   \n",
       "\n",
       "   org_good_cntr_share  org_fed_cntr_share  org_sub_cntr_share  \\\n",
       "0             0.990060                 1.0                 0.0   \n",
       "1             0.985011                 1.0                 0.0   \n",
       "2             0.968401                 1.0                 0.0   \n",
       "3             0.993682                 1.0                 0.0   \n",
       "4             0.740000                 1.0                 0.0   \n",
       "\n",
       "   org_mun_cntr_share  okpd_good_cntr_share  quarter  cntr_length  \\\n",
       "0                 0.0              1.011099        2          233   \n",
       "1                 0.0              1.010274        3          129   \n",
       "2                 0.0              1.036036        3           84   \n",
       "3                 0.0              1.079040        1           71   \n",
       "4                 0.0              1.070969        4           67   \n",
       "\n",
       "   one_day_price  \n",
       "0           1001  \n",
       "1           1981  \n",
       "2           1017  \n",
       "3           5752  \n",
       "4            788  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/4/grbs_finished.csv', encoding='utf-8')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_numerical(df, train=True):\n",
    "    \"\"\"Обработка количественных переменных\"\"\"\n",
    "    \n",
    "    if train:\n",
    "        process_numerical.cache = {}\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = load_scaler()\n",
    "    \n",
    "    for nv in df[num_var]:\n",
    "        if train:\n",
    "            ulimit = np.percentile(df[nv].values, 99)\n",
    "            dlimit = np.percentile(df[nv].values, 1)\n",
    "            process_numerical.cache[nv] = (dlimit, ulimit)\n",
    "        else:\n",
    "            ulimit = process_numerical.cache[nv][1]\n",
    "            dlimit = process_numerical.cache[nv][0]\n",
    "            \n",
    "        df.loc[df[nv] > ulimit, nv] = ulimit\n",
    "        df.loc[df[nv] < dlimit, nv] = dlimit\n",
    "    \n",
    "    for nv in df[num_var]:\n",
    "        df.loc[df[nv] < 1, nv] = 1\n",
    "        df.loc[:,nv] = np.log(df[nv])\n",
    "    \n",
    "    if train:\n",
    "        df.loc[:,num_var] = scaler.fit_transform(df[num_var])\n",
    "        # save_scaler(scaler)\n",
    "    else:\n",
    "        df.loc[:,num_var] = scaler.transform(df[num_var])\n",
    "        \n",
    "    return df\n",
    "\n",
    "def process_nominal(df, train=True):\n",
    "    \"\"\"Обработка номинальных переменных\"\"\"\n",
    "    \n",
    "    if train:\n",
    "        group_converters = {}\n",
    "        woe_converters = {}\n",
    "\n",
    "        for cv in cat_var:\n",
    "            cnt = df[cv].value_counts()\n",
    "            for val, count in zip(cnt.index, cnt.values):\n",
    "                if count / df.shape[0] <= 0.005:\n",
    "                    df.loc[df[cv] == val, cv] = 'NEW'\n",
    "\n",
    "            conv = {}\n",
    "            for val in set(df[cv]):\n",
    "                if val != 'NEW': conv[val] = val\n",
    "\n",
    "            group_converters[cv] = conv\n",
    "\n",
    "        for cv in cat_var:\n",
    "            cnt = df[cv].value_counts()\n",
    "            conv = {}\n",
    "            for val, count in zip(cnt.index, cnt.values):\n",
    "                good_with_val = df.loc[(df.cntr_result == 1) & (df[cv] == val)].shape[0]\n",
    "                bad_with_val = df.loc[(df.cntr_result == 0) & (df[cv] == val)].shape[0]\n",
    "\n",
    "                p = good_with_val / df.loc[df.cntr_result == 1].shape[0]\n",
    "                q = bad_with_val / df.loc[df.cntr_result == 0].shape[0]\n",
    "                woe = round(np.log(p / q), 3)\n",
    "\n",
    "                conv[val] = woe\n",
    "                df.loc[df[cv]==val, cv] = round(np.log(p / q), 3)\n",
    "\n",
    "            woe_converters[cv] = conv\n",
    "       \n",
    "        process_nominal.gp_convs = group_converters\n",
    "        process_nominal.woe_convs = woe_converters\n",
    "    else:\n",
    "        for cv in cat_var:\n",
    "            df.loc[:,cv] = df[cv].map(process_nominal.gp_convs[cv])\n",
    "            df.loc[:,cv] = df[cv].fillna('NEW')\n",
    "            df.loc[:,cv] = df[cv].map(process_nominal.woe_convs[cv])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список количественных переменных с нефиксированной областью значений\n",
    "num_var = [\n",
    "    'sup_cntr_num', 'sup_running_cntr_num', 'sup_cntr_avg_price', 'org_cntr_num', \n",
    "    'org_cntr_avg_price', 'org_running_cntr_num','price', 'pmp',\n",
    "    'cntr_num_together', 'cntr_length', 'one_day_price'\n",
    "]\n",
    "\n",
    "# Список количественных переменных с областью значений от 0 до 1\n",
    "# Без учета 'sup_okpd_exp'\n",
    "num_var01 = [\n",
    "        'sup_good_cntr_share', 'sup_fed_cntr_share', 'sup_sub_cntr_share', \n",
    "        'sup_mun_cntr_share', 'sup_cntr_avg_penalty_share', 'sup_1s_sev', 'sup_1s_org_sev',  \n",
    "        'sup_no_pnl_share', 'sup_sim_price_share', 'org_good_cntr_share', 'org_fed_cntr_share', \n",
    "        'org_sub_cntr_share', 'org_mun_cntr_share', 'org_1s_sev', 'org_1s_sup_sev', 'org_sim_price_share', \n",
    "        'okpd_good_cntr_share'\n",
    "    ]\n",
    "\n",
    "# Список категориальных переменных\n",
    "cat_var = ['org_type', 'okpd2', 'purch_type', 'quarter']\n",
    "\n",
    "# Список бинарных переменных\n",
    "cat_bin_var = ['price_higher_pmp', 'price_too_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_preprocess(df):\n",
    "    \"\"\"Начальная предобработка\"\"\"\n",
    "    \n",
    "    # Список бинарных переменных\n",
    "    cat_bin_var = ['price_higher_pmp', 'price_too_low']\n",
    "    \n",
    "    # Удаление неважных количественных переменных\n",
    "    f0or nv in ('cntr_num_together', 'price', 'pmp'):\n",
    "        num_var.remove(nv)\n",
    "\n",
    "    for nv01 in ('sup_cntr_avg_penalty_share', 'sup_1s_sev', 'sup_1s_org_sev', \n",
    "        'sup_no_pnl_share', 'org_fed_cntr_share', 'org_sub_cntr_share', \n",
    "        'org_mun_cntr_share', 'org_1s_sev', 'org_1s_sup_sev'):\n",
    "        num_var01.remove(nv01)\n",
    "\n",
    "    # Удаление бинарных переменных\n",
    "    cat_bin_var.clear()\n",
    "    \n",
    "    # Перемена местами обозначений целевой переменной: \"0\" соответствует хорошему контракту, \"1\" - плохому \n",
    "    df.loc[df.cntr_result == 0, 'cntr_result'] = 2\n",
    "    df.loc[df.cntr_result == 1, 'cntr_result'] = 0\n",
    "    df.loc[df.cntr_result == 2, 'cntr_result'] = 1\n",
    "    \n",
    "    # Предобработка\n",
    "    df = process_numerical(df)\n",
    "    df = process_nominal(df)\n",
    "    \n",
    "    # Формирование финального набора переменных\n",
    "    var = ['cntrID']\n",
    "    var.extend(num_var)\n",
    "    var.extend(num_var01)\n",
    "    var.extend(cat_var)\n",
    "    \n",
    "    return df[var + ['cntr_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier():\n",
    "    \"\"\"Набор классификаторов с параметрами\"\"\"\n",
    "    \n",
    "    classifiers = {\n",
    "        \"LogReg\": (LogisticRegression, ParameterGrid({\n",
    "            'random_state': [RANDOM_SEED],\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'penalty': ['l1', 'l2']\n",
    "            })),\n",
    "        \"RandForest\": (RandomForestClassifier, ParameterGrid({\n",
    "            'random_state': [RANDOM_SEED],\n",
    "            'n_estimators': [10, 100, 200, 400, 600, 800, 1000],\n",
    "            'max_depth': [3, 4, 6, 8]\n",
    "        })),\n",
    "        \"XGBoost\": (XGBClassifier, ParameterGrid({\n",
    "            'random_state': [RANDOM_SEED],\n",
    "            \"eta\": [0.03, 0.1, 0.3],\n",
    "            \"n_estimators\": [100, 200, 400, 800, 1000],\n",
    "            \"max_depth\": [3, 4, 6, 8],\n",
    "            \"logging_level\": ['Silent'],\n",
    "            'subsample': [0.7, 0.85, 1]\n",
    "        }))\n",
    "    }\n",
    "    \n",
    "    for clf_name in classifiers:\n",
    "        for params in classifiers[clf_name][1]:\n",
    "            yield clf_name, params, classifiers[clf_name][0](**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_classifier(X, y, kfolds=10, valid=0.2):\n",
    "    \"\"\"Выбор лучшего классификатора\"\"\"\n",
    "    \n",
    "    # TODO: Переделать процесс оценки качества модели\n",
    "    # TODO: Добавить дисперсию для каждой метрики на основе значений метрики в каждом фолде\n",
    "    \n",
    "    start_time = time.time()\n",
    "    LOG_FILE = 'logs.log'\n",
    "    \n",
    "    stats = np.array([])\n",
    "    row_names = []\n",
    "    column_names = [\n",
    "        'train_acc', 'train_auc', 'train_ll', 'test_acc', 'test_auc', 'test_ll',\n",
    "        'valid_acc', 'valid_auc', 'valid_ll', 'time'\n",
    "    ]\n",
    "    \n",
    "    best_clf_name = None\n",
    "    best_params = None\n",
    "    \n",
    "    best_test_log_loss = None\n",
    "    best_y_test_pred = None\n",
    "    best_y_test_pred_proba = None\n",
    "    best_y_test_real = None\n",
    "    \n",
    "    best_y_valid_pred = None\n",
    "    best_y_valid_pred_proba = np.zeros((0, 2))\n",
    "    best_y_valid_real = None\n",
    "    best_valid_log_loss = 100\n",
    "    \n",
    "    # Формирование обучающей и валидационной выборки\n",
    "    val_ind = int(X.shape[0] * valid)\n",
    "    X_valid, y_valid = X[:val_ind,:], y[:val_ind]\n",
    "    X, y = X[val_ind:,:], y[val_ind:]\n",
    "    \n",
    "    for clf_name, params, clf in get_classifier():\n",
    "        y_train_pred = np.array([])\n",
    "        y_train_real = np.array([])\n",
    "        y_train_pred_proba = np.zeros((0, 2))\n",
    "        \n",
    "        y_test_pred = np.array([])\n",
    "        y_test_pred_proba = np.zeros((0, 2))\n",
    "        y_test_real = np.array([])\n",
    "        \n",
    "        row_names.append(clf_name + ' ' + '_'.join(str(param) for param in params.values()))\n",
    "        \n",
    "        # Обучение модели на 10-кратной кросс-валидации\n",
    "        start_learning_time = time.time()\n",
    "        kfold_generator = StratifiedKFold(n_splits=kfolds)\n",
    "        for train_index, test_index in kfold_generator.split(X, y):\n",
    "            X_train = X[train_index]\n",
    "            y_train = y[train_index]\n",
    "\n",
    "            X_test = X[test_index]\n",
    "            y_test = y[test_index]\n",
    "            \n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            y_train_real = np.concatenate((y_train_real, y_train))\n",
    "            y_train_pred = np.concatenate((y_train_pred, clf.predict(X_train)))\n",
    "            y_train_pred_proba = np.concatenate((y_train_pred_proba, clf.predict_proba(X_train)))\n",
    "            \n",
    "            y_test_real = np.concatenate((y_test_real, y_test))\n",
    "            y_test_pred = np.concatenate((y_test_pred, clf.predict(X_test)))\n",
    "            y_test_pred_proba = np.concatenate((y_test_pred_proba, clf.predict_proba(X_test)))\n",
    "            \n",
    "        \n",
    "        learning_time = time.time() - start_learning_time\n",
    "        \n",
    "        # Выбор лучшего алгоритма\n",
    "        if log_loss(y_valid, clf.predict_proba(X_valid)) < best_valid_log_loss:\n",
    "            best_clf_name = clf_name\n",
    "            best_params = params\n",
    "            \n",
    "            best_y_test_pred = y_test_pred\n",
    "            best_y_test_pred_proba = y_test_pred_proba\n",
    "            best_y_test_real = y_test_real\n",
    "            best_test_log_loss = log_loss(y_test_real, y_test_pred_proba)\n",
    "            \n",
    "            best_y_valid_pred = clf.predict(X_valid)\n",
    "            best_y_valid_pred_proba = clf.predict_proba(X_valid)\n",
    "            best_y_valid_real = y_valid\n",
    "            best_valid_log_loss = log_loss(y_valid, best_y_valid_pred_proba)\n",
    "        \n",
    "        # Расчет метрик для тренировочной, тестовой, валидационной выборки\n",
    "        train_acc = accuracy_score(y_train_real, y_train_pred)\n",
    "        train_auc = roc_auc_score(y_train_real, y_train_pred)\n",
    "        train_ll = log_loss(y_train_real, y_train_pred_proba)\n",
    "\n",
    "        test_acc = accuracy_score(y_test_real, y_test_pred)\n",
    "        test_auc = roc_auc_score(y_test_real, y_test_pred)\n",
    "        test_ll = log_loss(y_test_real, y_test_pred_proba)\n",
    "\n",
    "        valid_acc = accuracy_score(y_valid, clf.predict(X_valid))\n",
    "        valid_auc = roc_auc_score(y_valid, clf.predict(X_valid))\n",
    "        valid_ll = log_loss(y_valid, clf.predict_proba(X_valid))\n",
    "        \n",
    "        metrics = [\n",
    "            train_acc, train_auc, train_ll,\n",
    "            test_acc, test_auc, test_ll,valid_acc, valid_auc, valid_ll,\n",
    "            int(learning_time)\n",
    "        ]\n",
    "        \n",
    "        key_metrics_str = (\n",
    "            '{} {}\\ntrain: ({:.3f}, {:.3f}, {:.3f}) '\n",
    "            'test: ({:.3f}, {:.3f}, {:.3f}) '\n",
    "            'valid: ({:.3f}, {:.3f}, {:.3f}) - {}\\n').format(\n",
    "                clf_name, params, train_acc, train_auc, train_ll,\n",
    "                test_acc, test_auc, test_ll, valid_acc, valid_auc, valid_ll,\n",
    "                int(learning_time)\n",
    "        )\n",
    "        print(key_metrics_str)\n",
    "        \n",
    "        # Добавление расчетов в массив\n",
    "        if stats.shape[0]:\n",
    "            stats = np.vstack((stats, np.array(metrics)))\n",
    "        else:\n",
    "            stats = np.array(metrics)\n",
    "            \n",
    "        # Запись логов\n",
    "        with open(LOG_FILE, 'a', encoding='utf-8') as file:\n",
    "            file.write(key_metrics_str)\n",
    "        \n",
    "    best_algorithm_str = 'Лучший алгоритм {} с параметрами {} с valid_acc: {:.3f}, valid_ll: {:.3f}\\n'.format(\n",
    "        best_clf_name,\n",
    "        best_params,\n",
    "        accuracy_score(best_y_valid_real, best_y_valid_pred),\n",
    "        log_loss(best_y_valid_real, best_y_valid_pred_proba)\n",
    "    )\n",
    "    print(best_algorithm_str)\n",
    "    with open(LOG_FILE, 'a', encoding='utf-8') as file:\n",
    "            file.write(best_algorithm_str)\n",
    "\n",
    "    print(classification_report(\n",
    "        best_y_valid_real,\n",
    "        best_y_valid_pred,\n",
    "        target_names=tuple(('Хороший', 'Плохой'))\n",
    "    ))\n",
    "    \n",
    "    time_consumed_str ='Выбор лучшего классификатора занял %s секунд' % int((time.time() - start_time))\n",
    "    print(time_consumed_str)\n",
    "    with open(LOG_FILE, 'a', encoding='utf-8') as file:\n",
    "            file.write(time_consumed_str)\n",
    "    \n",
    "    result = pd.DataFrame(data=stats, columns=column_names, index=row_names)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = initial_preprocess(data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35468, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntrID</th>\n",
       "      <th>sup_cntr_num</th>\n",
       "      <th>sup_running_cntr_num</th>\n",
       "      <th>sup_cntr_avg_price</th>\n",
       "      <th>org_cntr_num</th>\n",
       "      <th>org_cntr_avg_price</th>\n",
       "      <th>org_running_cntr_num</th>\n",
       "      <th>cntr_length</th>\n",
       "      <th>one_day_price</th>\n",
       "      <th>sup_good_cntr_share</th>\n",
       "      <th>...</th>\n",
       "      <th>sup_mun_cntr_share</th>\n",
       "      <th>sup_sim_price_share</th>\n",
       "      <th>org_good_cntr_share</th>\n",
       "      <th>org_sim_price_share</th>\n",
       "      <th>okpd_good_cntr_share</th>\n",
       "      <th>org_type</th>\n",
       "      <th>okpd2</th>\n",
       "      <th>purch_type</th>\n",
       "      <th>quarter</th>\n",
       "      <th>cntr_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33698468</td>\n",
       "      <td>-0.580939</td>\n",
       "      <td>-0.699322</td>\n",
       "      <td>-0.425817</td>\n",
       "      <td>-0.213088</td>\n",
       "      <td>-0.528096</td>\n",
       "      <td>0.428038</td>\n",
       "      <td>-0.366531</td>\n",
       "      <td>-0.705934</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1.070969</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27661203</td>\n",
       "      <td>-0.415206</td>\n",
       "      <td>-0.699322</td>\n",
       "      <td>0.387776</td>\n",
       "      <td>-1.048033</td>\n",
       "      <td>0.072870</td>\n",
       "      <td>-0.473172</td>\n",
       "      <td>1.073282</td>\n",
       "      <td>-0.215795</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.142</td>\n",
       "      <td>1.108748</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33682440</td>\n",
       "      <td>-0.580939</td>\n",
       "      <td>-0.699322</td>\n",
       "      <td>-0.151879</td>\n",
       "      <td>1.010943</td>\n",
       "      <td>2.178480</td>\n",
       "      <td>0.724813</td>\n",
       "      <td>1.400113</td>\n",
       "      <td>-0.554295</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.874825</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1.049705</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1.244</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34009214</td>\n",
       "      <td>-0.580939</td>\n",
       "      <td>-0.699322</td>\n",
       "      <td>2.854341</td>\n",
       "      <td>0.428582</td>\n",
       "      <td>1.230921</td>\n",
       "      <td>1.145543</td>\n",
       "      <td>-0.710917</td>\n",
       "      <td>1.605741</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.108748</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31700286</td>\n",
       "      <td>-0.181618</td>\n",
       "      <td>-0.243157</td>\n",
       "      <td>0.240404</td>\n",
       "      <td>-0.815883</td>\n",
       "      <td>0.624808</td>\n",
       "      <td>-1.532427</td>\n",
       "      <td>0.299480</td>\n",
       "      <td>0.613241</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1.013832</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>-0.081</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cntrID  sup_cntr_num  sup_running_cntr_num  sup_cntr_avg_price  \\\n",
       "4  33698468     -0.580939             -0.699322           -0.425817   \n",
       "5  27661203     -0.415206             -0.699322            0.387776   \n",
       "7  33682440     -0.580939             -0.699322           -0.151879   \n",
       "8  34009214     -0.580939             -0.699322            2.854341   \n",
       "9  31700286     -0.181618             -0.243157            0.240404   \n",
       "\n",
       "   org_cntr_num  org_cntr_avg_price  org_running_cntr_num  cntr_length  \\\n",
       "4     -0.213088           -0.528096              0.428038    -0.366531   \n",
       "5     -1.048033            0.072870             -0.473172     1.073282   \n",
       "7      1.010943            2.178480              0.724813     1.400113   \n",
       "8      0.428582            1.230921              1.145543    -0.710917   \n",
       "9     -0.815883            0.624808             -1.532427     0.299480   \n",
       "\n",
       "   one_day_price  sup_good_cntr_share     ...      sup_mun_cntr_share  \\\n",
       "4      -0.705934             0.666667     ...                     0.0   \n",
       "5      -0.215795             0.750000     ...                     0.0   \n",
       "7      -0.554295             0.666667     ...                     0.0   \n",
       "8       1.605741             0.666667     ...                     0.0   \n",
       "9       0.613241             0.833333     ...                     0.0   \n",
       "\n",
       "   sup_sim_price_share  org_good_cntr_share  org_sim_price_share  \\\n",
       "4                0.333             0.740000                0.111   \n",
       "5                0.250             0.619403                0.142   \n",
       "7                0.333             0.874825                0.088   \n",
       "8                0.333             0.819672                0.081   \n",
       "9                0.167             0.994286                0.074   \n",
       "\n",
       "   okpd_good_cntr_share  org_type  okpd2 purch_type quarter cntr_result  \n",
       "4              1.070969     0.218   1.62     -0.081  -0.039         1.0  \n",
       "5              1.108748    -0.356  0.435     -0.081   0.500         1.0  \n",
       "7              1.049705     0.041  1.244      0.238  -0.039         1.0  \n",
       "8              1.108748     0.218  0.435     -0.081  -0.039         1.0  \n",
       "9              1.013832     0.041 -0.677     -0.081  -0.172         1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Балансировка выборки\n",
    "bad_cntr = data.loc[data.cntr_result == 1]\n",
    "good_cntr = data.loc[data.cntr_result == 0].sample(bad_cntr.shape[0], random_state=RANDOM_SEED)\n",
    "data = bad_cntr.append(good_cntr)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['cntr_result', 'cntrID'], axis=1).values\n",
    "y = data.cntr_result.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRer {'C': 0.001, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.801, 0.801, 0.497) test: (0.800, 0.800, 0.497) valid: (0.801, 0.801, 0.495) - 1\n",
      "\n",
      "LogRer {'C': 0.001, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.835, 0.835, 0.426) test: (0.834, 0.834, 0.426) valid: (0.836, 0.836, 0.426) - 2\n",
      "\n",
      "LogRer {'C': 0.001, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.800, 0.800, 0.477) test: (0.800, 0.800, 0.477) valid: (0.802, 0.802, 0.472) - 1\n",
      "\n",
      "LogRer {'C': 0.001, 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.811, 0.811, 0.467) test: (0.811, 0.811, 0.467) valid: (0.816, 0.816, 0.462) - 2\n",
      "\n",
      "LogRer {'C': 0.01, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.885, 0.885, 0.283) test: (0.885, 0.885, 0.283) valid: (0.886, 0.886, 0.281) - 17\n",
      "\n",
      "LogRer {'C': 0.01, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.893, 0.893, 0.266) test: (0.892, 0.892, 0.267) valid: (0.891, 0.891, 0.264) - 2\n",
      "\n",
      "LogRer {'C': 0.01, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.865, 0.865, 0.343) test: (0.865, 0.865, 0.343) valid: (0.866, 0.866, 0.339) - 1\n",
      "\n",
      "LogRer {'C': 0.01, 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.872, 0.872, 0.329) test: (0.871, 0.871, 0.330) valid: (0.872, 0.872, 0.326) - 2\n",
      "\n",
      "LogRer {'C': 0.1, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.900, 0.900, 0.251) test: (0.899, 0.899, 0.251) valid: (0.898, 0.898, 0.247) - 31\n",
      "\n",
      "LogRer {'C': 0.1, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.900, 0.900, 0.250) test: (0.901, 0.901, 0.251) valid: (0.900, 0.900, 0.246) - 6\n",
      "\n",
      "LogRer {'C': 0.1, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.891, 0.891, 0.271) test: (0.891, 0.891, 0.271) valid: (0.889, 0.889, 0.267) - 2\n",
      "\n",
      "LogRer {'C': 0.1, 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.895, 0.895, 0.262) test: (0.895, 0.895, 0.263) valid: (0.893, 0.893, 0.260) - 6\n",
      "\n",
      "LogRer {'C': 1, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.900, 0.900, 0.250) valid: (0.903, 0.903, 0.245) - 184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRer {'C': 1, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 16\n",
      "\n",
      "LogRer {'C': 1, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.900, 0.900, 0.251) test: (0.900, 0.900, 0.252) valid: (0.899, 0.899, 0.247) - 3\n",
      "\n",
      "LogRer {'C': 1, 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.900, 0.900, 0.250) test: (0.900, 0.900, 0.251) valid: (0.901, 0.901, 0.246) - 13\n",
      "\n",
      "LogRer {'C': 10, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 40\n",
      "\n",
      "LogRer {'C': 10, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 16\n",
      "\n",
      "LogRer {'C': 10, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 3\n",
      "\n",
      "LogRer {'C': 10, 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 13\n",
      "\n",
      "LogRer {'C': 100, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 27\n",
      "\n",
      "LogRer {'C': 100, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 16\n",
      "\n",
      "LogRer {'C': 100, 'penalty': 'l2', 'random_state': 42, 'solver': 'liblinear'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 4\n",
      "\n",
      "LogRer {'C': 100, 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "train: (0.901, 0.901, 0.249) test: (0.901, 0.901, 0.250) valid: (0.903, 0.903, 0.245) - 13\n",
      "\n",
      "RandForest {'max_depth': 3, 'n_estimators': 10, 'random_state': 42}\n",
      "train: (0.907, 0.906, 0.377) test: (0.906, 0.906, 0.378) valid: (0.904, 0.904, 0.377) - 2\n",
      "\n",
      "RandForest {'max_depth': 3, 'n_estimators': 100, 'random_state': 42}\n",
      "train: (0.913, 0.913, 0.384) test: (0.912, 0.912, 0.386) valid: (0.915, 0.915, 0.384) - 16\n",
      "\n",
      "RandForest {'max_depth': 3, 'n_estimators': 200, 'random_state': 42}\n",
      "train: (0.914, 0.914, 0.375) test: (0.912, 0.912, 0.377) valid: (0.916, 0.916, 0.374) - 33\n",
      "\n",
      "RandForest {'max_depth': 3, 'n_estimators': 400, 'random_state': 42}\n",
      "train: (0.914, 0.914, 0.364) test: (0.912, 0.912, 0.366) valid: (0.916, 0.916, 0.362) - 67\n",
      "\n",
      "RandForest {'max_depth': 3, 'n_estimators': 600, 'random_state': 42}\n",
      "train: (0.913, 0.913, 0.364) test: (0.912, 0.912, 0.365) valid: (0.916, 0.916, 0.361) - 95\n",
      "\n",
      "RandForest {'max_depth': 3, 'n_estimators': 800, 'random_state': 42}\n",
      "train: (0.913, 0.913, 0.366) test: (0.912, 0.912, 0.368) valid: (0.915, 0.915, 0.363) - 129\n",
      "\n",
      "RandForest {'max_depth': 3, 'n_estimators': 1000, 'random_state': 42}\n",
      "train: (0.913, 0.913, 0.364) test: (0.912, 0.912, 0.365) valid: (0.916, 0.916, 0.360) - 149\n",
      "\n",
      "RandForest {'max_depth': 4, 'n_estimators': 10, 'random_state': 42}\n",
      "train: (0.912, 0.912, 0.321) test: (0.911, 0.911, 0.325) valid: (0.914, 0.914, 0.322) - 2\n",
      "\n",
      "RandForest {'max_depth': 4, 'n_estimators': 100, 'random_state': 42}\n",
      "train: (0.916, 0.916, 0.323) test: (0.914, 0.914, 0.326) valid: (0.920, 0.920, 0.320) - 18\n",
      "\n",
      "RandForest {'max_depth': 4, 'n_estimators': 200, 'random_state': 42}\n",
      "train: (0.917, 0.917, 0.324) test: (0.915, 0.915, 0.327) valid: (0.920, 0.921, 0.319) - 36\n",
      "\n",
      "RandForest {'max_depth': 4, 'n_estimators': 400, 'random_state': 42}\n",
      "train: (0.917, 0.917, 0.320) test: (0.915, 0.915, 0.323) valid: (0.921, 0.921, 0.317) - 72\n",
      "\n",
      "RandForest {'max_depth': 4, 'n_estimators': 600, 'random_state': 42}\n",
      "train: (0.917, 0.917, 0.320) test: (0.915, 0.915, 0.323) valid: (0.920, 0.920, 0.317) - 107\n",
      "\n",
      "RandForest {'max_depth': 4, 'n_estimators': 800, 'random_state': 42}\n",
      "train: (0.917, 0.917, 0.319) test: (0.915, 0.915, 0.322) valid: (0.920, 0.920, 0.315) - 145\n",
      "\n",
      "RandForest {'max_depth': 4, 'n_estimators': 1000, 'random_state': 42}\n",
      "train: (0.916, 0.916, 0.318) test: (0.915, 0.915, 0.321) valid: (0.920, 0.920, 0.314) - 176\n",
      "\n",
      "RandForest {'max_depth': 6, 'n_estimators': 10, 'random_state': 42}\n",
      "train: (0.920, 0.920, 0.241) test: (0.915, 0.915, 0.249) valid: (0.921, 0.921, 0.241) - 2\n",
      "\n",
      "RandForest {'max_depth': 6, 'n_estimators': 100, 'random_state': 42}\n",
      "train: (0.922, 0.922, 0.254) test: (0.918, 0.918, 0.262) valid: (0.924, 0.924, 0.247) - 23\n",
      "\n",
      "RandForest {'max_depth': 6, 'n_estimators': 200, 'random_state': 42}\n",
      "train: (0.922, 0.922, 0.253) test: (0.918, 0.918, 0.261) valid: (0.926, 0.926, 0.250) - 45\n",
      "\n",
      "RandForest {'max_depth': 6, 'n_estimators': 400, 'random_state': 42}\n",
      "train: (0.923, 0.923, 0.251) test: (0.918, 0.918, 0.259) valid: (0.926, 0.926, 0.252) - 90\n",
      "\n",
      "RandForest {'max_depth': 6, 'n_estimators': 600, 'random_state': 42}\n",
      "train: (0.922, 0.922, 0.251) test: (0.918, 0.918, 0.259) valid: (0.926, 0.926, 0.251) - 135\n",
      "\n",
      "RandForest {'max_depth': 6, 'n_estimators': 800, 'random_state': 42}\n",
      "train: (0.923, 0.922, 0.251) test: (0.918, 0.918, 0.259) valid: (0.925, 0.925, 0.252) - 180\n",
      "\n",
      "RandForest {'max_depth': 6, 'n_estimators': 1000, 'random_state': 42}\n",
      "train: (0.922, 0.922, 0.251) test: (0.918, 0.918, 0.259) valid: (0.925, 0.925, 0.251) - 225\n",
      "\n",
      "RandForest {'max_depth': 8, 'n_estimators': 10, 'random_state': 42}\n",
      "train: (0.930, 0.930, 0.200) test: (0.917, 0.917, 0.222) valid: (0.924, 0.924, 0.227) - 3\n",
      "\n",
      "RandForest {'max_depth': 8, 'n_estimators': 100, 'random_state': 42}\n",
      "train: (0.932, 0.932, 0.207) test: (0.921, 0.921, 0.228) valid: (0.927, 0.927, 0.223) - 29\n",
      "\n",
      "RandForest {'max_depth': 8, 'n_estimators': 200, 'random_state': 42}\n",
      "train: (0.932, 0.932, 0.206) test: (0.920, 0.920, 0.226) valid: (0.927, 0.927, 0.221) - 55\n",
      "\n",
      "RandForest {'max_depth': 8, 'n_estimators': 400, 'random_state': 42}\n",
      "train: (0.932, 0.932, 0.204) test: (0.920, 0.920, 0.225) valid: (0.927, 0.927, 0.219) - 110\n",
      "\n",
      "RandForest {'max_depth': 8, 'n_estimators': 600, 'random_state': 42}\n",
      "train: (0.932, 0.932, 0.204) test: (0.920, 0.920, 0.225) valid: (0.927, 0.927, 0.220) - 165\n",
      "\n",
      "RandForest {'max_depth': 8, 'n_estimators': 800, 'random_state': 42}\n",
      "train: (0.932, 0.932, 0.204) test: (0.920, 0.920, 0.225) valid: (0.927, 0.927, 0.218) - 220\n",
      "\n",
      "RandForest {'max_depth': 8, 'n_estimators': 1000, 'random_state': 42}\n",
      "train: (0.932, 0.932, 0.204) test: (0.920, 0.920, 0.224) valid: (0.926, 0.926, 0.218) - 274\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.925, 0.925, 0.170) test: (0.920, 0.920, 0.179) valid: (0.927, 0.927, 0.170) - 20\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.925, 0.925, 0.170) test: (0.920, 0.920, 0.179) valid: (0.930, 0.930, 0.169) - 19\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.924, 0.924, 0.171) test: (0.920, 0.920, 0.180) valid: (0.929, 0.929, 0.170) - 18\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.933, 0.933, 0.155) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.166) - 40\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.933, 0.933, 0.156) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.165) - 38\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.930, 0.930, 0.159) test: (0.921, 0.921, 0.177) valid: (0.931, 0.931, 0.165) - 35\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.943, 0.943, 0.136) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.166) - 80\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.930, 0.930, 0.164) - 76\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.940, 0.940, 0.142) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.165) - 69\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.958, 0.958, 0.110) test: (0.924, 0.924, 0.179) valid: (0.929, 0.929, 0.168) - 161\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.958, 0.958, 0.110) test: (0.924, 0.924, 0.178) valid: (0.930, 0.931, 0.167) - 153\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.955, 0.955, 0.116) test: (0.923, 0.923, 0.178) valid: (0.929, 0.929, 0.166) - 137\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.964, 0.964, 0.100) test: (0.923, 0.923, 0.180) valid: (0.929, 0.929, 0.168) - 202\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.964, 0.964, 0.100) test: (0.924, 0.924, 0.179) valid: (0.931, 0.931, 0.169) - 192\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.961, 0.961, 0.106) test: (0.923, 0.923, 0.180) valid: (0.929, 0.929, 0.167) - 171\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.931, 0.931, 0.159) test: (0.921, 0.921, 0.177) valid: (0.930, 0.930, 0.166) - 26\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.931, 0.931, 0.159) test: (0.922, 0.922, 0.177) valid: (0.929, 0.929, 0.166) - 25\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.929, 0.929, 0.162) test: (0.921, 0.921, 0.177) valid: (0.930, 0.930, 0.167) - 23\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.931, 0.932, 0.164) - 53\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.942, 0.942, 0.138) test: (0.923, 0.923, 0.175) valid: (0.931, 0.931, 0.164) - 50\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.939, 0.939, 0.143) test: (0.923, 0.923, 0.175) valid: (0.931, 0.931, 0.164) - 46\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.960, 0.960, 0.107) test: (0.924, 0.924, 0.177) valid: (0.929, 0.929, 0.166) - 106\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.960, 0.960, 0.108) test: (0.924, 0.924, 0.177) valid: (0.930, 0.930, 0.164) - 101\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.955, 0.955, 0.115) test: (0.924, 0.924, 0.176) valid: (0.927, 0.927, 0.165) - 91\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.982, 0.982, 0.070) test: (0.922, 0.922, 0.186) valid: (0.926, 0.926, 0.175) - 214\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.981, 0.981, 0.071) test: (0.923, 0.923, 0.184) valid: (0.929, 0.929, 0.170) - 207\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.977, 0.977, 0.079) test: (0.923, 0.923, 0.183) valid: (0.927, 0.927, 0.169) - 183\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.988, 0.988, 0.058) test: (0.921, 0.921, 0.191) valid: (0.927, 0.927, 0.179) - 269\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.988, 0.988, 0.059) test: (0.922, 0.922, 0.189) valid: (0.926, 0.926, 0.174) - 253\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.984, 0.984, 0.067) test: (0.923, 0.923, 0.187) valid: (0.926, 0.926, 0.173) - 228\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.946, 0.946, 0.131) test: (0.923, 0.923, 0.175) valid: (0.930, 0.930, 0.165) - 39\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.946, 0.946, 0.133) test: (0.923, 0.923, 0.175) valid: (0.932, 0.932, 0.164) - 39\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.931, 0.932, 0.163) - 37\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.970, 0.970, 0.092) test: (0.924, 0.924, 0.177) valid: (0.928, 0.928, 0.168) - 81\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.969, 0.969, 0.094) test: (0.924, 0.924, 0.175) valid: (0.932, 0.932, 0.164) - 77\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.964, 0.964, 0.102) test: (0.924, 0.924, 0.176) valid: (0.930, 0.930, 0.163) - 71\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.994, 0.994, 0.049) test: (0.923, 0.923, 0.188) valid: (0.927, 0.927, 0.178) - 167\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.993, 0.993, 0.051) test: (0.923, 0.923, 0.186) valid: (0.931, 0.931, 0.171) - 157\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.988, 0.988, 0.060) test: (0.923, 0.922, 0.183) valid: (0.930, 0.930, 0.168) - 141\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.018) test: (0.922, 0.922, 0.214) valid: (0.925, 0.925, 0.201) - 338\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.019) test: (0.922, 0.922, 0.210) valid: (0.929, 0.929, 0.192) - 316\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.999, 0.999, 0.024) test: (0.921, 0.921, 0.205) valid: (0.930, 0.930, 0.185) - 289\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.012) test: (0.921, 0.921, 0.226) valid: (0.924, 0.924, 0.211) - 424\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.013) test: (0.921, 0.921, 0.222) valid: (0.929, 0.929, 0.203) - 397\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.017) test: (0.921, 0.921, 0.216) valid: (0.929, 0.929, 0.195) - 356\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.968, 0.968, 0.095) test: (0.923, 0.923, 0.177) valid: (0.929, 0.929, 0.167) - 52\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.968, 0.968, 0.097) test: (0.923, 0.923, 0.176) valid: (0.932, 0.932, 0.166) - 51\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.964, 0.964, 0.103) test: (0.923, 0.923, 0.176) valid: (0.932, 0.932, 0.165) - 49\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.993, 0.993, 0.049) test: (0.922, 0.922, 0.185) valid: (0.928, 0.928, 0.175) - 112\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.993, 0.993, 0.052) test: (0.923, 0.923, 0.183) valid: (0.929, 0.929, 0.171) - 107\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.988, 0.988, 0.060) test: (0.923, 0.923, 0.181) valid: (0.931, 0.931, 0.168) - 98\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.018) test: (0.922, 0.922, 0.208) valid: (0.928, 0.928, 0.193) - 231\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.019) test: (0.923, 0.923, 0.204) valid: (0.927, 0.927, 0.189) - 218\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.999, 0.999, 0.024) test: (0.923, 0.923, 0.200) valid: (0.928, 0.928, 0.182) - 199\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.006) test: (0.922, 0.922, 0.245) valid: (0.926, 0.926, 0.223) - 459\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.006) test: (0.921, 0.921, 0.240) valid: (0.926, 0.926, 0.222) - 437\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.008) test: (0.922, 0.922, 0.233) valid: (0.927, 0.927, 0.212) - 399\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.004) test: (0.921, 0.921, 0.257) valid: (0.925, 0.925, 0.234) - 573\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.004) test: (0.922, 0.922, 0.253) valid: (0.925, 0.925, 0.234) - 546\n",
      "\n",
      "XGBoost {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.005) test: (0.921, 0.921, 0.246) valid: (0.928, 0.928, 0.224) - 497\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.925, 0.925, 0.170) test: (0.920, 0.920, 0.179) valid: (0.927, 0.927, 0.170) - 20\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.925, 0.925, 0.170) test: (0.920, 0.920, 0.179) valid: (0.930, 0.930, 0.169) - 19\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.924, 0.924, 0.171) test: (0.920, 0.920, 0.180) valid: (0.929, 0.929, 0.170) - 18\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.933, 0.933, 0.155) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.166) - 40\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.933, 0.933, 0.156) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.165) - 38\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.930, 0.930, 0.159) test: (0.921, 0.921, 0.177) valid: (0.931, 0.931, 0.165) - 35\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.943, 0.943, 0.136) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.166) - 80\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.930, 0.930, 0.164) - 76\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.940, 0.940, 0.142) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.165) - 69\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.958, 0.958, 0.110) test: (0.924, 0.924, 0.179) valid: (0.929, 0.929, 0.168) - 161\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.958, 0.958, 0.110) test: (0.924, 0.924, 0.178) valid: (0.930, 0.931, 0.167) - 152\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.955, 0.955, 0.116) test: (0.923, 0.923, 0.178) valid: (0.929, 0.929, 0.166) - 137\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.964, 0.964, 0.100) test: (0.923, 0.923, 0.180) valid: (0.929, 0.929, 0.168) - 201\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.964, 0.964, 0.100) test: (0.924, 0.924, 0.179) valid: (0.931, 0.931, 0.169) - 190\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.961, 0.961, 0.106) test: (0.923, 0.923, 0.180) valid: (0.929, 0.929, 0.167) - 171\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.931, 0.931, 0.159) test: (0.921, 0.921, 0.177) valid: (0.930, 0.930, 0.166) - 26\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.931, 0.931, 0.159) test: (0.922, 0.922, 0.177) valid: (0.929, 0.929, 0.166) - 25\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.929, 0.929, 0.162) test: (0.921, 0.921, 0.177) valid: (0.930, 0.930, 0.167) - 23\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.931, 0.932, 0.164) - 53\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.942, 0.942, 0.138) test: (0.923, 0.923, 0.175) valid: (0.931, 0.931, 0.164) - 50\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.939, 0.939, 0.143) test: (0.923, 0.923, 0.175) valid: (0.931, 0.931, 0.164) - 46\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.960, 0.960, 0.107) test: (0.924, 0.924, 0.177) valid: (0.929, 0.929, 0.166) - 106\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.960, 0.960, 0.108) test: (0.924, 0.924, 0.177) valid: (0.930, 0.930, 0.164) - 101\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.955, 0.955, 0.115) test: (0.924, 0.924, 0.176) valid: (0.927, 0.927, 0.165) - 91\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.982, 0.982, 0.070) test: (0.922, 0.922, 0.186) valid: (0.926, 0.926, 0.175) - 214\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.981, 0.981, 0.071) test: (0.923, 0.923, 0.184) valid: (0.929, 0.929, 0.170) - 203\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.977, 0.977, 0.079) test: (0.923, 0.923, 0.183) valid: (0.927, 0.927, 0.169) - 182\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.988, 0.988, 0.058) test: (0.921, 0.921, 0.191) valid: (0.927, 0.927, 0.179) - 269\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.988, 0.988, 0.059) test: (0.922, 0.922, 0.189) valid: (0.926, 0.926, 0.174) - 253\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.984, 0.984, 0.067) test: (0.923, 0.923, 0.187) valid: (0.926, 0.926, 0.173) - 227\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.946, 0.946, 0.131) test: (0.923, 0.923, 0.175) valid: (0.930, 0.930, 0.165) - 39\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.946, 0.946, 0.133) test: (0.923, 0.923, 0.175) valid: (0.932, 0.932, 0.164) - 38\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.931, 0.932, 0.163) - 35\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.970, 0.970, 0.092) test: (0.924, 0.924, 0.177) valid: (0.928, 0.928, 0.168) - 81\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.969, 0.969, 0.094) test: (0.924, 0.924, 0.175) valid: (0.932, 0.932, 0.164) - 77\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.964, 0.964, 0.102) test: (0.924, 0.924, 0.176) valid: (0.930, 0.930, 0.163) - 71\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.994, 0.994, 0.049) test: (0.923, 0.923, 0.188) valid: (0.927, 0.927, 0.178) - 167\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.993, 0.993, 0.051) test: (0.923, 0.923, 0.186) valid: (0.931, 0.931, 0.171) - 157\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.988, 0.988, 0.060) test: (0.923, 0.922, 0.183) valid: (0.930, 0.930, 0.168) - 142\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.018) test: (0.922, 0.922, 0.214) valid: (0.925, 0.925, 0.201) - 339\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.019) test: (0.922, 0.922, 0.210) valid: (0.929, 0.929, 0.192) - 317\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.999, 0.999, 0.024) test: (0.921, 0.921, 0.205) valid: (0.930, 0.930, 0.185) - 285\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.012) test: (0.921, 0.921, 0.226) valid: (0.924, 0.924, 0.211) - 427\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.013) test: (0.921, 0.921, 0.222) valid: (0.929, 0.929, 0.203) - 401\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.017) test: (0.921, 0.921, 0.216) valid: (0.929, 0.929, 0.195) - 356\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.968, 0.968, 0.095) test: (0.923, 0.923, 0.177) valid: (0.929, 0.929, 0.167) - 52\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.968, 0.968, 0.097) test: (0.923, 0.923, 0.176) valid: (0.932, 0.932, 0.166) - 52\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.964, 0.964, 0.103) test: (0.923, 0.923, 0.176) valid: (0.932, 0.932, 0.165) - 49\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.993, 0.993, 0.049) test: (0.922, 0.922, 0.185) valid: (0.928, 0.928, 0.175) - 112\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.993, 0.993, 0.052) test: (0.923, 0.923, 0.183) valid: (0.929, 0.929, 0.171) - 107\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.988, 0.988, 0.060) test: (0.923, 0.923, 0.181) valid: (0.931, 0.931, 0.168) - 98\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.018) test: (0.922, 0.922, 0.208) valid: (0.928, 0.928, 0.193) - 231\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.019) test: (0.923, 0.923, 0.204) valid: (0.927, 0.927, 0.189) - 218\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.999, 0.999, 0.024) test: (0.923, 0.923, 0.200) valid: (0.928, 0.928, 0.182) - 199\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.006) test: (0.922, 0.922, 0.245) valid: (0.926, 0.926, 0.223) - 463\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.006) test: (0.921, 0.921, 0.240) valid: (0.926, 0.926, 0.222) - 438\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.008) test: (0.922, 0.922, 0.233) valid: (0.927, 0.927, 0.212) - 399\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.004) test: (0.921, 0.921, 0.257) valid: (0.925, 0.925, 0.234) - 575\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.004) test: (0.922, 0.922, 0.253) valid: (0.925, 0.925, 0.234) - 549\n",
      "\n",
      "XGBoost {'eta': 0.1, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.005) test: (0.921, 0.921, 0.246) valid: (0.928, 0.928, 0.224) - 499\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.925, 0.925, 0.170) test: (0.920, 0.920, 0.179) valid: (0.927, 0.927, 0.170) - 20\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.925, 0.925, 0.170) test: (0.920, 0.920, 0.179) valid: (0.930, 0.930, 0.169) - 19\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.924, 0.924, 0.171) test: (0.920, 0.920, 0.180) valid: (0.929, 0.929, 0.170) - 18\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.933, 0.933, 0.155) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.166) - 40\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.933, 0.933, 0.156) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.165) - 38\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.930, 0.930, 0.159) test: (0.921, 0.921, 0.177) valid: (0.931, 0.931, 0.165) - 35\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.943, 0.943, 0.136) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.166) - 81\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.930, 0.930, 0.164) - 77\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.940, 0.940, 0.142) test: (0.922, 0.922, 0.176) valid: (0.931, 0.931, 0.165) - 69\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.958, 0.958, 0.110) test: (0.924, 0.924, 0.179) valid: (0.929, 0.929, 0.168) - 162\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.958, 0.958, 0.110) test: (0.924, 0.924, 0.178) valid: (0.930, 0.931, 0.167) - 154\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.955, 0.955, 0.116) test: (0.923, 0.923, 0.178) valid: (0.929, 0.929, 0.166) - 137\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.964, 0.964, 0.100) test: (0.923, 0.923, 0.180) valid: (0.929, 0.929, 0.168) - 202\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.964, 0.964, 0.100) test: (0.924, 0.924, 0.179) valid: (0.931, 0.931, 0.169) - 192\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 3, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.961, 0.961, 0.106) test: (0.923, 0.923, 0.180) valid: (0.929, 0.929, 0.167) - 173\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.931, 0.931, 0.159) test: (0.921, 0.921, 0.177) valid: (0.930, 0.930, 0.166) - 26\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.931, 0.931, 0.159) test: (0.922, 0.922, 0.177) valid: (0.929, 0.929, 0.166) - 25\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.929, 0.929, 0.162) test: (0.921, 0.921, 0.177) valid: (0.930, 0.930, 0.167) - 23\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.931, 0.932, 0.164) - 53\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.942, 0.942, 0.138) test: (0.923, 0.923, 0.175) valid: (0.931, 0.931, 0.164) - 51\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.939, 0.939, 0.143) test: (0.923, 0.923, 0.175) valid: (0.931, 0.931, 0.164) - 46\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.960, 0.960, 0.107) test: (0.924, 0.924, 0.177) valid: (0.929, 0.929, 0.166) - 107\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.960, 0.960, 0.108) test: (0.924, 0.924, 0.177) valid: (0.930, 0.930, 0.164) - 101\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.955, 0.955, 0.115) test: (0.924, 0.924, 0.176) valid: (0.927, 0.927, 0.165) - 91\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.982, 0.982, 0.070) test: (0.922, 0.922, 0.186) valid: (0.926, 0.926, 0.175) - 215\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.981, 0.981, 0.071) test: (0.923, 0.923, 0.184) valid: (0.929, 0.929, 0.170) - 203\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.977, 0.977, 0.079) test: (0.923, 0.923, 0.183) valid: (0.927, 0.927, 0.169) - 182\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.988, 0.988, 0.058) test: (0.921, 0.921, 0.191) valid: (0.927, 0.927, 0.179) - 269\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.988, 0.988, 0.059) test: (0.922, 0.922, 0.189) valid: (0.926, 0.926, 0.174) - 254\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 4, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.984, 0.984, 0.067) test: (0.923, 0.923, 0.187) valid: (0.926, 0.926, 0.173) - 228\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.946, 0.946, 0.131) test: (0.923, 0.923, 0.175) valid: (0.930, 0.930, 0.165) - 39\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.946, 0.946, 0.133) test: (0.923, 0.923, 0.175) valid: (0.932, 0.932, 0.164) - 38\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.943, 0.943, 0.137) test: (0.923, 0.923, 0.175) valid: (0.931, 0.932, 0.163) - 35\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.970, 0.970, 0.092) test: (0.924, 0.924, 0.177) valid: (0.928, 0.928, 0.168) - 81\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.969, 0.969, 0.094) test: (0.924, 0.924, 0.175) valid: (0.932, 0.932, 0.164) - 77\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.964, 0.964, 0.102) test: (0.924, 0.924, 0.176) valid: (0.930, 0.930, 0.163) - 71\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.994, 0.994, 0.049) test: (0.923, 0.923, 0.188) valid: (0.927, 0.927, 0.178) - 167\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.993, 0.993, 0.051) test: (0.923, 0.923, 0.186) valid: (0.931, 0.931, 0.171) - 158\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.988, 0.988, 0.060) test: (0.923, 0.922, 0.183) valid: (0.930, 0.930, 0.168) - 143\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.018) test: (0.922, 0.922, 0.214) valid: (0.925, 0.925, 0.201) - 341\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.019) test: (0.922, 0.922, 0.210) valid: (0.929, 0.929, 0.192) - 319\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.999, 0.999, 0.024) test: (0.921, 0.921, 0.205) valid: (0.930, 0.930, 0.185) - 287\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.012) test: (0.921, 0.921, 0.226) valid: (0.924, 0.924, 0.211) - 427\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.013) test: (0.921, 0.921, 0.222) valid: (0.929, 0.929, 0.203) - 402\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.017) test: (0.921, 0.921, 0.216) valid: (0.929, 0.929, 0.195) - 360\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.968, 0.968, 0.095) test: (0.923, 0.923, 0.177) valid: (0.929, 0.929, 0.167) - 52\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.968, 0.968, 0.097) test: (0.923, 0.923, 0.176) valid: (0.932, 0.932, 0.166) - 52\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 100, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.964, 0.964, 0.103) test: (0.923, 0.923, 0.176) valid: (0.932, 0.932, 0.165) - 49\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (0.993, 0.993, 0.049) test: (0.922, 0.922, 0.185) valid: (0.928, 0.928, 0.175) - 112\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (0.993, 0.993, 0.052) test: (0.923, 0.923, 0.183) valid: (0.929, 0.929, 0.171) - 107\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 200, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.988, 0.988, 0.060) test: (0.923, 0.923, 0.181) valid: (0.931, 0.931, 0.168) - 99\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.018) test: (0.922, 0.922, 0.208) valid: (0.928, 0.928, 0.193) - 232\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.019) test: (0.923, 0.923, 0.204) valid: (0.927, 0.927, 0.189) - 220\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 400, 'random_state': 42, 'subsample': 1}\n",
      "train: (0.999, 0.999, 0.024) test: (0.923, 0.923, 0.200) valid: (0.928, 0.928, 0.182) - 200\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.006) test: (0.922, 0.922, 0.245) valid: (0.926, 0.926, 0.223) - 462\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.006) test: (0.921, 0.921, 0.240) valid: (0.926, 0.926, 0.222) - 439\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 800, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.008) test: (0.922, 0.922, 0.233) valid: (0.927, 0.927, 0.212) - 400\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.7}\n",
      "train: (1.000, 1.000, 0.004) test: (0.921, 0.921, 0.257) valid: (0.925, 0.925, 0.234) - 575\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 0.85}\n",
      "train: (1.000, 1.000, 0.004) test: (0.922, 0.922, 0.253) valid: (0.925, 0.925, 0.234) - 549\n",
      "\n",
      "XGBoost {'eta': 0.3, 'logging_level': 'Silent', 'max_depth': 8, 'n_estimators': 1000, 'random_state': 42, 'subsample': 1}\n",
      "train: (1.000, 1.000, 0.005) test: (0.921, 0.921, 0.246) valid: (0.928, 0.928, 0.224) - 499\n",
      "\n",
      "Лучший алгоритм XGBoost с параметрами {'eta': 0.03, 'logging_level': 'Silent', 'max_depth': 6, 'n_estimators': 100, 'random_state': 42, 'subsample': 1} с valid_acc: 0.931, valid_ll: 0.163\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Хороший       0.96      0.90      0.93      3551\n",
      "     Плохой       0.91      0.96      0.93      3542\n",
      "\n",
      "avg / total       0.93      0.93      0.93      7093\n",
      "\n",
      "Выбор лучшего классификатора занял 34105 секунд\n"
     ]
    }
   ],
   "source": [
    "result = choose_best_classifier(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Экспорт результатов\n",
    "result.to_csv(path_or_buf='parameter_tuning_v4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
